from models.chat import ChatRequest, ChatResponse
import openai
import os
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# OpenAI API í´ë¼ì´ì–¸íŠ¸ ìƒì„±
client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

async def generate_text(chat_request: ChatRequest) -> ChatResponse:
    try:
        # print(f"ğŸ“¡ OpenAI API í˜¸ì¶œ: {chat_request}")  # ìš”ì²­ ë°ì´í„° ì¶œë ¥

        response = client.chat.completions.create(
            model="gpt-4",  # gpt-4 ë˜ëŠ” gpt-3.5-turbo
            messages=[
                {"role": "system", "content": "You are a helpful assistant."},  # ì‹œìŠ¤í…œ ë©”ì‹œì§€
                {"role": "user", "content": chat_request.prompt},               # ì‚¬ìš©ì ë©”ì‹œì§€
            ],
            max_tokens=chat_request.max_tokens,
            temperature=chat_request.temperature,
        )

        # ì‘ë‹µ ë°ì´í„° ë³€í™˜
        response_text = response.choices[0].message.content
        # print(f"âœ… OpenAI API ì‘ë‹µ: {response_text}")  # ì‘ë‹µ ë‚´ìš© ì¶œë ¥

        return ChatResponse(response=response_text)
    except Exception as e:
        # print(f"âŒ OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")  # ì—ëŸ¬ ë©”ì‹œì§€ ì¶œë ¥
        raise ValueError(f"OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")